{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1000)\n",
    "\n",
    "with open('objs.pkl', 'rb') as f:\n",
    "    X_train, Y_train, X_test, Y_test = pickle.load(f)\n",
    "\n",
    "X_train = X_train[:10000]\n",
    "Y_train = Y_train[:10000]\n",
    "\n",
    "X_test = X_test[:1000]\n",
    "Y_test = Y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 2.2899 - acc: 0.1217 - val_loss: 2.2611 - val_acc: 0.2470\n",
      "Epoch 2/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 2.1323 - acc: 0.2111 - val_loss: 2.0263 - val_acc: 0.2880\n",
      "Epoch 3/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.9637 - acc: 0.2681 - val_loss: 1.9009 - val_acc: 0.3320\n",
      "Epoch 4/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.8620 - acc: 0.3022 - val_loss: 1.8009 - val_acc: 0.3690\n",
      "Epoch 5/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.7923 - acc: 0.3337 - val_loss: 1.7637 - val_acc: 0.3660\n",
      "Epoch 6/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.7405 - acc: 0.3551 - val_loss: 1.7418 - val_acc: 0.3800\n",
      "Epoch 7/250\n",
      "10000/10000 [==============================] - 58s 6ms/step - loss: 1.7014 - acc: 0.3666 - val_loss: 1.6458 - val_acc: 0.4060\n",
      "Epoch 8/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.6606 - acc: 0.3863 - val_loss: 1.6155 - val_acc: 0.4300\n",
      "Epoch 9/250\n",
      "10000/10000 [==============================] - 59s 6ms/step - loss: 1.6213 - acc: 0.3959 - val_loss: 1.6020 - val_acc: 0.4150\n",
      "Epoch 10/250\n",
      "10000/10000 [==============================] - 59s 6ms/step - loss: 1.5879 - acc: 0.4135 - val_loss: 1.5527 - val_acc: 0.4540\n",
      "Epoch 11/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.5697 - acc: 0.4163 - val_loss: 1.5135 - val_acc: 0.4650\n",
      "Epoch 12/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.5218 - acc: 0.4419 - val_loss: 1.4833 - val_acc: 0.4710\n",
      "Epoch 13/250\n",
      "10000/10000 [==============================] - 58s 6ms/step - loss: 1.5000 - acc: 0.4502 - val_loss: 1.4420 - val_acc: 0.4830\n",
      "Epoch 14/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.4755 - acc: 0.4582 - val_loss: 1.4199 - val_acc: 0.4950\n",
      "Epoch 15/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.4352 - acc: 0.4701 - val_loss: 1.4393 - val_acc: 0.4910\n",
      "Epoch 16/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.4186 - acc: 0.4773 - val_loss: 1.3809 - val_acc: 0.5160\n",
      "Epoch 17/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.4059 - acc: 0.4814 - val_loss: 1.3610 - val_acc: 0.5180\n",
      "Epoch 18/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.3822 - acc: 0.4952 - val_loss: 1.3642 - val_acc: 0.5120\n",
      "Epoch 19/250\n",
      "10000/10000 [==============================] - 58s 6ms/step - loss: 1.3644 - acc: 0.5006 - val_loss: 1.3540 - val_acc: 0.5230\n",
      "Epoch 20/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.3556 - acc: 0.5013 - val_loss: 1.3286 - val_acc: 0.5310\n",
      "Epoch 21/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.3322 - acc: 0.5166 - val_loss: 1.2974 - val_acc: 0.5460\n",
      "Epoch 22/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.3117 - acc: 0.5304 - val_loss: 1.2822 - val_acc: 0.5450\n",
      "Epoch 23/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.2930 - acc: 0.5318 - val_loss: 1.2740 - val_acc: 0.5530\n",
      "Epoch 24/250\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 1.2829 - acc: 0.5374 - val_loss: 1.2640 - val_acc: 0.5550\n",
      "Epoch 25/250\n",
      "10000/10000 [==============================] - 58s 6ms/step - loss: 1.2669 - acc: 0.5348 - val_loss: 1.2379 - val_acc: 0.5700\n",
      "Epoch 26/250\n",
      "10000/10000 [==============================] - 71s 7ms/step - loss: 1.2492 - acc: 0.5487 - val_loss: 1.2411 - val_acc: 0.5650\n",
      "Epoch 27/250\n",
      "10000/10000 [==============================] - 67s 7ms/step - loss: 1.2411 - acc: 0.5557 - val_loss: 1.2343 - val_acc: 0.5680\n",
      "Epoch 28/250\n",
      "10000/10000 [==============================] - 64s 6ms/step - loss: 1.2206 - acc: 0.5587 - val_loss: 1.1995 - val_acc: 0.5810\n",
      "Epoch 29/250\n",
      "10000/10000 [==============================] - 74s 7ms/step - loss: 1.2067 - acc: 0.5641 - val_loss: 1.1938 - val_acc: 0.5830\n",
      "Epoch 30/250\n",
      "10000/10000 [==============================] - 95s 9ms/step - loss: 1.1981 - acc: 0.5651 - val_loss: 1.1809 - val_acc: 0.5960\n",
      "Epoch 31/250\n",
      "10000/10000 [==============================] - 118s 12ms/step - loss: 1.1850 - acc: 0.5777 - val_loss: 1.1721 - val_acc: 0.5900\n",
      "Epoch 32/250\n",
      "10000/10000 [==============================] - 117s 12ms/step - loss: 1.1663 - acc: 0.5833 - val_loss: 1.1716 - val_acc: 0.5890\n",
      "Epoch 33/250\n",
      "10000/10000 [==============================] - 109s 11ms/step - loss: 1.1593 - acc: 0.5883 - val_loss: 1.1638 - val_acc: 0.5990\n",
      "Epoch 34/250\n",
      "10000/10000 [==============================] - 109s 11ms/step - loss: 1.1516 - acc: 0.5826 - val_loss: 1.1627 - val_acc: 0.6020\n",
      "Epoch 35/250\n",
      "10000/10000 [==============================] - 112s 11ms/step - loss: 1.1292 - acc: 0.6006 - val_loss: 1.1557 - val_acc: 0.6050\n",
      "Epoch 36/250\n",
      "10000/10000 [==============================] - 111s 11ms/step - loss: 1.1231 - acc: 0.5981 - val_loss: 1.1660 - val_acc: 0.6010\n",
      "Epoch 37/250\n",
      "10000/10000 [==============================] - 114s 11ms/step - loss: 1.1085 - acc: 0.6047 - val_loss: 1.1386 - val_acc: 0.6060\n",
      "Epoch 38/250\n",
      "10000/10000 [==============================] - 115s 11ms/step - loss: 1.0997 - acc: 0.6098 - val_loss: 1.1258 - val_acc: 0.6090\n",
      "Epoch 39/250\n",
      "10000/10000 [==============================] - 122s 12ms/step - loss: 1.0864 - acc: 0.6119 - val_loss: 1.1195 - val_acc: 0.6030\n",
      "Epoch 40/250\n",
      "10000/10000 [==============================] - 115s 12ms/step - loss: 1.0727 - acc: 0.6171 - val_loss: 1.0998 - val_acc: 0.6210\n",
      "Epoch 41/250\n",
      "10000/10000 [==============================] - 115s 12ms/step - loss: 1.0580 - acc: 0.6200 - val_loss: 1.1041 - val_acc: 0.6080\n",
      "Epoch 42/250\n",
      "10000/10000 [==============================] - 155s 15ms/step - loss: 1.0550 - acc: 0.6222 - val_loss: 1.1103 - val_acc: 0.6100\n",
      "Epoch 43/250\n",
      "10000/10000 [==============================] - 166s 17ms/step - loss: 1.0472 - acc: 0.6295 - val_loss: 1.1145 - val_acc: 0.6110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27e13704780>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train / 255.0, to_categorical(Y_train),\n",
    "          batch_size=128, shuffle=True, epochs=250,\n",
    "          validation_data=(X_test / 255.0, to_categorical(Y_test)),\n",
    "          callbacks=[EarlyStopping(min_delta=0.001, patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
